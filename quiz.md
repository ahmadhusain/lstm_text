1.  When working with text dataset on classification task, there is *tokenization* step that aims to separate each word in the entire document into a token form. We need to do *feature selection* before modeling. Which of the argument on `text_tokenizer` below is appropriate to setting the maximum number of words to be used?
    - [ ] `lower`
    - [ ] `num_words`
    - [ ] `fit_text_tokenizer`
2.  If we want to create matrix result of the transformation each text in a sequence of integer, which of the function below is appropriate?
    - [ ] `text_tokenizer()`
    - [ ] `pad_sequences()`
    - [ ] `text_to_sequences()`
3.  Suppose we want to predict unseen text data, of course we need to do pre-processing step first. Which of information from model that we need to keep when doing text-processing? 
    - [ ] tokenizer
    - [ ] epoch
    - [ ] batch size


